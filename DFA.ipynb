{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total intra-class covariance matrix (W):\n",
      "              LCB           LSM            LBM         LP           LM    \\\n",
      "LCB    70166.944444  36126.587302  7473.134921  2907.956349  2022.908730   \n",
      "LSM    36126.587302  20150.396825  1862.301587  1526.706349  1034.325397   \n",
      " LBM    7473.134921   1862.301587  7990.753968   482.718254   260.146825   \n",
      "LP      2907.956349   1526.706349   482.718254   204.831349   108.974206   \n",
      "LM      2022.908730   1034.325397   260.146825   108.974206    93.399603   \n",
      "LAM     2907.531746   1442.341270   513.103175   149.091270   115.103968   \n",
      "\n",
      "               LAM  \n",
      "LCB    2907.531746  \n",
      "LSM    1442.341270  \n",
      " LBM    513.103175  \n",
      "LP      149.091270  \n",
      "LM      115.103968  \n",
      "LAM     361.976984  \n",
      "\n",
      "\n",
      "\n",
      "Total inter-class covariance matrix (B):\n",
      "               LCB            LSM             LBM          LP            LM    \\\n",
      "LCB    188171.666667  135466.666667  51011.666667  60854.166667  26479.500000   \n",
      "LSM    135466.666667   97523.809524  36723.809524  43809.523810  19062.857143   \n",
      " LBM    51011.666667   36723.809524  13828.809524  16497.023810   7178.357143   \n",
      "LP      60854.166667   43809.523810  16497.023810  19680.059524   8563.392857   \n",
      "LM      26479.500000   19062.857143   7178.357143   8563.392857   3726.192857   \n",
      "LAM     43942.000000   31634.285714  11912.285714  14210.714286   6183.514286   \n",
      "\n",
      "                LAM  \n",
      "LCB    43942.000000  \n",
      "LSM    31634.285714  \n",
      " LBM   11912.285714  \n",
      "LP     14210.714286  \n",
      "LM      6183.514286  \n",
      "LAM    10261.371429  \n",
      "\n",
      "Total variance matrix (V):\n",
      "               LCB            LSM             LBM          LP            LM    \\\n",
      "LCB    258338.611111  171593.253968  58484.801587  63762.123016  28502.408730   \n",
      "LSM    171593.253968  117674.206349  38586.111111  45336.230159  20097.182540   \n",
      " LBM    58484.801587   38586.111111  21819.563492  16979.742063   7438.503968   \n",
      "LP      63762.123016   45336.230159  16979.742063  19884.890873   8672.367063   \n",
      "LM      28502.408730   20097.182540   7438.503968   8672.367063   3819.592460   \n",
      "LAM     46849.531746   33076.626984  12425.388889  14359.805556   6298.618254   \n",
      "\n",
      "                LAM  \n",
      "LCB    46849.531746  \n",
      "LSM    33076.626984  \n",
      " LBM   12425.388889  \n",
      "LP     14359.805556  \n",
      "LM      6298.618254  \n",
      "LAM    10623.348413  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file\n",
    "# Replace 'chienloup.csv' with the exact path to your file\n",
    "data = pd.read_csv('chienloup.csv', sep=';')\n",
    "\n",
    "# Extract quantitative and qualitative variables names\n",
    "quantitative_vars = data.columns[1:-1]  # Quantitative variables\n",
    "qualitative_var = data.columns[-1]     # Qualitative variable (e.g., category)\n",
    "\n",
    "# Group the data by the qualitative variable\n",
    "groups = data.groupby(qualitative_var)\n",
    "\n",
    "# Initialize a dictionary to store intra-class covariance matrices\n",
    "W_k_dict = {}\n",
    "\n",
    "# Initilize the intraclass variance matrix\n",
    "W = np.zeros((len(quantitative_vars), len(quantitative_vars)))\n",
    "\n",
    "# Compute W_k for each group as well as W\n",
    "for group_name, group in groups:\n",
    "    group_values = group[quantitative_vars].values\n",
    "    group_mean = np.mean(group_values, axis=0)\n",
    "    n_k = group_values.shape[0]  # Number of samples in the group\n",
    "    # Calculate W_k: intra-class covariance matrix\n",
    "    W_k = (group_values - group_mean).T @ (group_values - group_mean) / n_k\n",
    "    W_k_dict[group_name] = W_k  # Store each W_k with the corresponding group name\n",
    "    W += W_k * n_k\n",
    "\n",
    "W = W/data.shape[0]\n",
    "\n",
    "###(Bonus)############################################################################################################################\n",
    "# We compute and visualize the correlation matrix from the covariance matrix to interpret the values of the intra covariances\n",
    "#for group_name, W_k in W_k_dict.items():\n",
    "#    print(f\"Intra-class correlation matrix W_k for group '{group_name}':\")\n",
    "#    # Computation of the correlation matrix from the covariance matrix\n",
    "#    std_dev = np.sqrt(np.diag(W_k))  # Standard deviations\n",
    "#    correlation_matrix = W_k / np.outer(std_dev, std_dev)  # Normalize to get correlations\n",
    "#\n",
    "#    # Visualization of the correlation matrix\n",
    "#    plt.figure(figsize=(8, 6))\n",
    "#    plt.imshow(correlation_matrix, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "#    plt.colorbar(label=\"Correlation\")\n",
    "#    plt.xticks(ticks=range(len(quantitative_vars)), labels=quantitative_vars, rotation=45, ha=\"right\")\n",
    "#    plt.yticks(ticks=range(len(quantitative_vars)), labels=quantitative_vars)\n",
    "#    plt.title(\"Correlation Matrix Heatmap\")\n",
    "#    plt.tight_layout()\n",
    "#    plt.show()\n",
    "#\n",
    "####################################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Computation of inter-class covariance matrix (B), which measures variability between group means\n",
    "overall_mean = np.mean(data[quantitative_vars].values, axis=0)  # Overall mean vector\n",
    "B = np.zeros((len(quantitative_vars), len(quantitative_vars)))  # Initialize inter-class covariance matrix\n",
    "\n",
    "for name, group in groups:\n",
    "    group_size = len(group)  # Number of samples in the current group\n",
    "    group_mean = np.mean(group[quantitative_vars].values, axis=0)  # Mean vector of the group\n",
    "    diff = (group_mean - overall_mean).reshape(-1, 1)  # Difference vector reshaped as a column\n",
    "    B += group_size * (diff @ diff.T)  # Weighted outer product of the difference vector\n",
    "\n",
    "# Computation of total variance matrix (V) as the sum of intra-class (W) and inter-class (B) covariances\n",
    "V = W + B\n",
    "\n",
    "# Displaying intra-class (W), inter-class (B), and total variance (V) matrices\n",
    "print(f\"Total intra-class covariance matrix (W):\")\n",
    "print(pd.DataFrame(W, index=quantitative_vars, columns=quantitative_vars))\n",
    "print(\"\\n\")\n",
    "print(\"\\nTotal inter-class covariance matrix (B):\")\n",
    "print(pd.DataFrame(B, index=quantitative_vars, columns=quantitative_vars))\n",
    "print(\"\\nTotal variance matrix (V):\")\n",
    "print(pd.DataFrame(V, index=quantitative_vars, columns=quantitative_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coumputation of V^-1.B and its eigen values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace of Inter-class covariance matrix (B): 333191.90952380927\n",
      "Trace of Total variance matrix (V): 432160.2126984125\n",
      "Proportion of variance explained by inter-class variability: 77.10%\n"
     ]
    }
   ],
   "source": [
    "# Compute the trace of B and V\n",
    "trace_B = np.trace(B)  # Sum of diagonal elements of B\n",
    "trace_V = np.trace(V)  # Sum of diagonal elements of V\n",
    "\n",
    "# Display the results\n",
    "print(f\"Trace of Inter-class covariance matrix (B): {trace_B}\")\n",
    "print(f\"Trace of Total variance matrix (V): {trace_V}\")\n",
    "\n",
    "# Compare the traces\n",
    "print(f\"Proportion of variance explained by inter-class variability: {trace_B / trace_V:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation of V, W, B:\n",
    "The inter-class variance, which is the trace of B, accounts for 0.77% of the total variance. This shows that the original variables separate the classes' groups quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of V^-1 * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues of V^-1 * B:\n",
      " [ 9.94925042e-01+0.00000000e+00j  2.27611276e-14+0.00000000e+00j\n",
      "  1.38879934e-14+0.00000000e+00j -7.47444178e-15+3.77105478e-15j\n",
      " -7.47444178e-15-3.77105478e-15j -1.41794016e-15+0.00000000e+00j]\n",
      "\n",
      "Sum of eigenvalues: (0.9949250416627787+0j)\n"
     ]
    }
   ],
   "source": [
    "# Compute V^-1 * B\n",
    "V_inv = np.linalg.inv(V)\n",
    "V_inv_B = V_inv @ B\n",
    "\n",
    "# Compute the eigenvalues of V^-1 * B\n",
    "eigenvalues, _ = np.linalg.eig(V_inv_B)\n",
    "\n",
    "# Display the eigenvalues and their sum\n",
    "print(\"Eigenvalues of V^-1 * B:\\n\", eigenvalues)\n",
    "print(\"\\nSum of eigenvalues:\", np.sum(eigenvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Etudiez les matrices V-1 et B : dimension, caract√©ristiques : Pouvez toujours diagonaliser directement ùëâ\n",
    "‚àí1ùêµ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of V^-1: (6, 6)\n",
      "Dimension of B: (6, 6)\n",
      "Dimension of V^-1 * B: (6, 6)\n",
      "Rank of V^-1 * B: 4\n",
      "Condition number of V^-1 * B: 9773931263870940.0\n"
     ]
    }
   ],
   "source": [
    "# Study the matrices\n",
    "print(\"Dimension of V^-1:\", V_inv.shape)\n",
    "print(\"Dimension of B:\", B.shape)\n",
    "\n",
    "\n",
    "# Study V^-1 * B\n",
    "print(\"Dimension of V^-1 * B:\", V_inv_B.shape)\n",
    "\n",
    "# Compute the rank of V^-1 * B\n",
    "rank_V_inv_B = np.linalg.matrix_rank(V_inv_B)\n",
    "\n",
    "# Compute the condition number (high values indicate collinearity)\n",
    "cond_number = np.linalg.cond(V_inv_B)\n",
    "\n",
    "# Display results\n",
    "print(\"Rank of V^-1 * B:\", rank_V_inv_B)\n",
    "print(\"Condition number of V^-1 * B:\", cond_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentary on V-1.B diagonalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe that the rank computed for V^-1 * B is 4, while its size is 6x6. ()\n",
    "# This indicates that the collinearity between its columns is so high that the computer estimates it as a set of nearly collinear vectors.\n",
    "# This is further confirmed by the very high value of the condition number.\n",
    "\n",
    "# Additionally, in the above computation of the eigenvalues of V^-1 * B, we observed that some eigenvalues were complex numbers.\n",
    "# This indicates numerical instability, which suggests that the matrix is close to being non-invertible.\n",
    "\n",
    "# In conclusion, V^-1 * B is not always invertible due to high collinearity between its columns.\n",
    "# This is caused by the low rank of B, which determines the rank of V^-1 * B. \n",
    "# In this case, since the number of classes is q = 2, the rank of B is at most q-1 = 1.\n",
    "# The above computed value of 4 for V^-1.B rank is due to wrong approximation made by the computer of the eigen values that are = 0 but estimated as slightly higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Si vous choisissez de diagonalisation cette matrice, utiliser le compl√©ment sur la diagonalisation donn√©e en cours\n",
    "(technique de r√©gularisation). Apres diagonalisation comme en ACP vous obtiendrez la projection des individus dans\n",
    "un nouvel espace par une m√©thode factorielle par projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues (Œª): [1.39501568e-16 6.42928785e-16 8.80691405e-15 1.52139095e-14\n",
      " 3.95012658e-14 9.94925042e-01]\n",
      "Eigenvectors (w) of C'Œ£^(-1)C:\n",
      "[[ 3.11466899e-09 -1.01562193e-08 -6.31130972e-09 -7.35489693e-09\n",
      "  -2.92605273e-10  1.00000000e+00]\n",
      " [-3.51895541e-02  2.94038595e-01  3.85270679e-01  3.96720101e-01\n",
      "  -7.78769969e-01  8.21745009e-09]\n",
      " [-2.52545321e-01  6.34973955e-01 -8.71517872e-02  5.40267569e-01\n",
      "   4.83264376e-01  1.08005059e-08]\n",
      " [-4.30715455e-01 -6.89746255e-02  8.21882155e-01 -2.37350143e-01\n",
      "   2.79108099e-01  4.16415015e-09]\n",
      " [ 7.83736365e-01  4.41446214e-01  3.20679128e-01 -2.47354135e-01\n",
      "   1.63900515e-01  2.29494447e-09]\n",
      " [-3.67728245e-01  5.57420059e-01 -2.56214150e-01 -6.58183072e-01\n",
      "  -2.34964184e-01  2.79964834e-10]]\n",
      "Transformed eigenvectors (v):\n",
      "[[-2.30161932e-11  3.01017848e-11  7.72894203e-10  2.17918757e-10\n",
      "  -3.08972750e-09  3.22180872e-04]\n",
      " [-3.18459924e-11  1.03842008e-10 -1.58585698e-09 -6.73051874e-10\n",
      "   5.45242490e-09 -7.28432556e-06]\n",
      " [ 1.05137773e-10  2.02489960e-10 -5.30503490e-10  3.81812893e-11\n",
      "   1.62494986e-09  1.47897225e-04]\n",
      " [-2.02391783e-11 -1.66470726e-10 -3.27676164e-09 -3.94959399e-09\n",
      "  -1.46409628e-08 -6.92955581e-03]\n",
      " [ 9.73130868e-11 -7.79253908e-10  4.27359482e-09  2.06576070e-08\n",
      "   1.82336986e-08 -1.47391477e-03]\n",
      " [ 4.40728523e-11  1.60190028e-11  4.15770291e-09 -5.88119762e-09\n",
      "   3.82391143e-09 -8.65874809e-04]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Use SVD for decomposition of B into CC^T\n",
    "U, S, _ = np.linalg.svd(B)  # SVD of B\n",
    "C = U @ np.diag(np.sqrt(S))  # Construct C\n",
    "\n",
    "# Compute the matrix C'Œ£^(-1)C\n",
    "C_T = C.T  # Transpose of C\n",
    "C_Sigma_inv_C_T = C_T @ V_inv @ C\n",
    "\n",
    "# Check if the matrix is symmetric (it should be)\n",
    "# print(\"Is C'Œ£^(-1)C symmetric?:\", np.allclose(C_Sigma_inv_C_T, C_Sigma_inv_C_T.T))\n",
    "\n",
    "# Diagonalize the symmetric matrix C'Œ£^(-1)C\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(C_Sigma_inv_C_T)  # eigh ensures symmetric diagonalization\n",
    "\n",
    "# Compute the transformation vector v using equation \n",
    "v_vectors = V_inv @ C @ eigenvectors\n",
    "\n",
    "# Results\n",
    "print(\"Eigenvalues of :\", eigenvalues)\n",
    "print(\"Eigenvectors (w) of C'Œ£^(-1)C:\")\n",
    "print(eigenvectors)\n",
    "\n",
    "print(\"Transformed eigenvectors (v):\")\n",
    "print(v_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projection of X onto the space spanned by eigen vectors explaining at least 80% of the variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate the explained variance\n",
    "explained_variance_ratio = eigenvalues / np.sum(eigenvalues)  # Explained variance ratio\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)  # Cumulative explained variance\n",
    "\n",
    "# Find the number of components needed to explain at least 80% of the variance\n",
    "n_components = np.argmax(cumulative_explained_variance >= 0.8) + 1\n",
    "\n",
    "print(f\"Number of components to explain 80% of variance: {n_components}\")\n",
    "print(\"Cumulative explained variance:\", cumulative_explained_variance)\n",
    "\n",
    "# Step 3: Select the top n_components eigenvectors\n",
    "selected_v_vectors = v_vectors[:, :n_components]\n",
    "\n",
    "# Step 4: Project the data onto the selected eigenvectors\n",
    "Z = X @ selected_v_vectors  # X is the centered data matrix\n",
    "\n",
    "# Step 5: Visualize the projection\n",
    "plt.scatter(Z[:, 0], Z[:, 1], c=y, cmap='viridis', edgecolor='k')  # y contains class labels\n",
    "plt.title(\"Projection on top components explaining >= 80% variance\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.colorbar(label=\"Class\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
